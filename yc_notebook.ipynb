{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import argparse\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def load_yoga_postures(posture_dir):\n",
    "    yoga_postures = []\n",
    "    yoga_posture_labels = []\n",
    "\n",
    "    for posture_name in os.listdir(posture_dir):\n",
    "        if posture_name.startswith(\".\"):\n",
    "            continue\n",
    "        posture_folder = os.path.join(posture_dir, posture_name)\n",
    "        for image_name in os.listdir(posture_folder):\n",
    "            if image_name.startswith(\".\"):\n",
    "                continue\n",
    "            image_path = os.path.join(posture_folder, image_name)\n",
    "            if image_name.endswith(\".jpg\") or image_name.endswith(\".png\"):\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                image = cv2.resize(image, (64, 64))\n",
    "                yoga_postures.append(image)\n",
    "                yoga_posture_labels.append(posture_name)\n",
    "\n",
    "    return yoga_postures, yoga_posture_labels\n",
    "\n",
    "def train_svm_model(X_train, yoga_posture_labels):\n",
    "    svm = SVC(kernel=\"linear\", C=1.0, random_state=42)\n",
    "    svm.fit(X_train, yoga_posture_labels)\n",
    "    return svm\n",
    "\n",
    "def classify_posture(frame, pose, svm, threshold=0.75):\n",
    "        # Convert the frame to grayscale\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Detect the pose landmarks using Mediapipe\n",
    "        results = pose.process(frame_gray)\n",
    "        if results.pose_landmarks is not None:\n",
    "            # Extract the pose landmarks and calculate the HOG features\n",
    "            landmarks = np.array([[lmk.x, lmk.y] for lmk in results.pose_landmarks.landmark])\n",
    "            landmarks = landmarks.flatten()\n",
    "            # Predict the posture using the SVM model\n",
    "            scores = svm.decision_function([landmarks])\n",
    "            if np.max(scores) >= threshold:\n",
    "                posture_pred = svm.predict([landmarks])[0]\n",
    "            else:\n",
    "                posture_pred = None\n",
    "        else:\n",
    "            posture_pred = None\n",
    "        return posture_pred\n",
    "\n",
    "def display_posture(frame, pose, posture_pred):\n",
    "    # Draw the pose landmarks and the predicted posture on the frame\n",
    "    mp_drawing.draw_landmarks(frame, pose.process(frame).pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "    cv2.putText(frame, posture_pred, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def save_video(frame, out):\n",
    "    out.write(frame)\n",
    "\n",
    "def yoga_classifier(input_path, display=False, output_path=None, save_model_path=None):\n",
    "    # Load the yoga postures and their labels\n",
    "    posture_dir = \"/home/khaleb.dabakuyo@Digital-Grenoble.local/Documents/ACV/Panther_trainer2/assets/images/train\"\n",
    "    yoga_postures, yoga_posture_labels = load_yoga_postures(posture_dir)\n",
    "\n",
    "    if save_model_path is not None and os.path.exists(save_model_path):\n",
    "        # Load the saved SVM model\n",
    "        svm = joblib.load(save_model_path)\n",
    "    else:\n",
    "        # Extract features from the images using mediapipe\n",
    "        X_train = []\n",
    "        for posture in yoga_postures:\n",
    "            results = mp_pose.Pose().process(posture)\n",
    "            if results.pose_landmarks is not None:\n",
    "                landmarks = np.array([[lmk.x, lmk.y] for lmk in results.pose_landmarks.landmark])\n",
    "                landmarks = landmarks.flatten()\n",
    "                X_train.append(landmarks)\n",
    "        X_train = np.array(X_train)\n",
    "        # Train a SVM model on the extracted features\n",
    "        svm = train_svm_model(X_train, yoga_posture_labels)\n",
    "        if save_model_path is not None:\n",
    "            # Save the trained SVM model\n",
    "            joblib.dump(svm, save_model_path)\n",
    "\n",
    "    # Initialize Mediapipe pose detection\n",
    "    pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "    # Use the trained model to classify new images of the yoga postures\n",
    "    if input_path == \"camera\":\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "    if output_path is not None:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, 20.0, (640, 480))\n",
    "    start_time = time.time()\n",
    "    posture_timer = 0\n",
    "    posture_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        posture_pred = classify_posture(frame, pose, svm)\n",
    "        if posture_pred == \"maintained\":\n",
    "            posture_timer = time.time() - start_time\n",
    "            if posture_timer >= 30:\n",
    "                # Flash the image\n",
    "                cv2.imshow('frame', frame)\n",
    "                cv2.waitKey(1000)\n",
    "                cv2.imshow('frame', np.zeros_like(frame))\n",
    "                cv2.waitKey(1000)\n",
    "                # Display progress line\n",
    "                posture_count += 1\n",
    "                progress = int((posture_timer / 30) * 100)\n",
    "                cv2.putText(frame, f\"Progress: {progress}%\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        else:\n",
    "            start_time = time.time()\n",
    "            posture_timer = 0\n",
    "        if display:\n",
    "            display = display_posture(frame, pose, posture_pred)\n",
    "            if not display:\n",
    "                break\n",
    "        if output_path is not None:\n",
    "            save_video(frame, out)\n",
    "    cap.release()\n",
    "    if output_path is not None:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n",
      "Premature end of JPEG file\n",
      "I0000 00:00:1700046578.734850   30009 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1700046578.795137   30872 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 525.125.06), renderer: NVIDIA GeForce GTX 1650/PCIe/SSE2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/khaleb.dabakuyo@Digital-Grenoble.local/Documents/ACV/Panther_trainer2/yc_notebook.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/khaleb.dabakuyo%40Digital-Grenoble.local/Documents/ACV/Panther_trainer2/yc_notebook.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m yoga_classifier(\u001b[39m'\u001b[39m\u001b[39mcamera\u001b[39m\u001b[39m'\u001b[39m, display\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, output_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, save_model_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrue\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/khaleb.dabakuyo@Digital-Grenoble.local/Documents/ACV/Panther_trainer2/yc_notebook.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/khaleb.dabakuyo%40Digital-Grenoble.local/Documents/ACV/Panther_trainer2/yc_notebook.ipynb#W1sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m X_train \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/khaleb.dabakuyo%40Digital-Grenoble.local/Documents/ACV/Panther_trainer2/yc_notebook.ipynb#W1sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39mfor\u001b[39;00m posture \u001b[39min\u001b[39;00m yoga_postures:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/khaleb.dabakuyo%40Digital-Grenoble.local/Documents/ACV/Panther_trainer2/yc_notebook.ipynb#W1sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     results \u001b[39m=\u001b[39m mp_pose\u001b[39m.\u001b[39mPose()\u001b[39m.\u001b[39mprocess(posture)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/khaleb.dabakuyo%40Digital-Grenoble.local/Documents/ACV/Panther_trainer2/yc_notebook.ipynb#W1sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m     \u001b[39mif\u001b[39;00m results\u001b[39m.\u001b[39mpose_landmarks \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/khaleb.dabakuyo%40Digital-Grenoble.local/Documents/ACV/Panther_trainer2/yc_notebook.ipynb#W1sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m         landmarks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[lmk\u001b[39m.\u001b[39mx, lmk\u001b[39m.\u001b[39my] \u001b[39mfor\u001b[39;00m lmk \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mpose_landmarks\u001b[39m.\u001b[39mlandmark])\n",
      "File \u001b[0;32m~/anaconda3/envs/acv/lib/python3.11/site-packages/mediapipe/python/solutions/pose.py:185\u001b[0m, in \u001b[0;36mPose.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(\u001b[39mself\u001b[39m, image: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NamedTuple:\n\u001b[1;32m    165\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mprocess(input_data\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m: image})\n\u001b[1;32m    186\u001b[0m   \u001b[39mif\u001b[39;00m results\u001b[39m.\u001b[39mpose_landmarks:  \u001b[39m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[39mfor\u001b[39;00m landmark \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mpose_landmarks\u001b[39m.\u001b[39mlandmark:  \u001b[39m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/acv/lib/python3.11/site-packages/mediapipe/python/solution_base.py:360\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    355\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSolutionBase can only process non-audio and non-proto-list data. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    356\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_stream_type_info[stream_name]\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    357\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtype is not supported yet.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    358\u001b[0m \u001b[39melif\u001b[39;00m (input_stream_type \u001b[39m==\u001b[39m PacketDataType\u001b[39m.\u001b[39mIMAGE_FRAME \u001b[39mor\u001b[39;00m\n\u001b[1;32m    359\u001b[0m       input_stream_type \u001b[39m==\u001b[39m PacketDataType\u001b[39m.\u001b[39mIMAGE):\n\u001b[0;32m--> 360\u001b[0m   \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m] \u001b[39m!=\u001b[39m RGB_CHANNELS:\n\u001b[1;32m    361\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInput image must contain three channel rgb data.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    362\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    363\u001b[0m       stream\u001b[39m=\u001b[39mstream_name,\n\u001b[1;32m    364\u001b[0m       packet\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_packet(input_stream_type,\n\u001b[1;32m    365\u001b[0m                                data)\u001b[39m.\u001b[39mat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_simulated_timestamp))\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "yoga_classifier('camera', display=True, output_path=None, save_model_path='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from streamClassifier.utils import build_dataframe\n",
    "from streamClassifier.config import num_to_class_dict, class_to_num_dict\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import os\n",
    "from PoseClassification.bootstrap_copy import BootstrapHelper\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "\n",
    "\n",
    "class SvcClassifier:\n",
    "    def __init__(self, training_csv_dir: str, stream_csv_dir:str):\n",
    "        self.model = None\n",
    "        self._training_dataset = self._get_training_dataset(training_csv_dir)\n",
    "        self._stream_csv_dir = stream_csv_dir\n",
    "\n",
    "    def _get_training_dataset(self, training_csv_dir) -> pd.DataFrame:\n",
    "        df = build_dataframe(source_dir=training_csv_dir)\n",
    "        return df\n",
    "\n",
    "    def _prepare_X_y_set(self) -> tuple:\n",
    "        df = self._training_dataset\n",
    "        X = df.drop(\n",
    "            [\"filename\", \"class\", \"class_num\"], axis=1\n",
    "        )  # Assuming 'label' is the column with class names/numbers\n",
    "        y = df[\"class_num\"]\n",
    "        return X, y\n",
    "    \n",
    "    def get_training_data_infos(self) -> dict:\n",
    "        infos = {\n",
    "            \"number_of_samples\": len(self._training_dataset),\n",
    "            \"num_class_0\": len(self._training_dataset[self._training_dataset[\"class_num\"] == 0]),\n",
    "            \"num_class_1\": len(self._training_dataset[self._training_dataset[\"class_num\"] == 1]),\n",
    "            \"num_class_2\": len(self._training_dataset[self._training_dataset[\"class_num\"] == 2]),\n",
    "            \"num_class_3\": len(self._training_dataset[self._training_dataset[\"class_num\"] == 3]),\n",
    "            \"num_class_4\": len(self._training_dataset[self._training_dataset[\"class_num\"] == 4]),\n",
    "        }\n",
    "        return infos\n",
    "    \n",
    "    def get_precision_infos(self):\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(self._confusion_matrix)\n",
    "        print(\"Classification Report:\")\n",
    "        print(self._classification_report)\n",
    "    \n",
    "    def fit(self,  show_value: bool = True):\n",
    "        \"\"\"\n",
    "        Evaluates the model\n",
    "        \"\"\"\n",
    "        # Assuming X is your feature matrix and y is the target vector\n",
    "        X, y = self._prepare_X_y_set()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=42\n",
    "        )\n",
    "\n",
    "        svc = SVC(kernel=\"linear\")  # You can change the kernel based on your data characteristics\n",
    "        svc.fit(X_train, y_train)\n",
    "        y_pred = svc.predict(X_test)\n",
    "\n",
    "        self._confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "        self._classification_report = classification_report(y_test, y_pred)\n",
    "        self.model = svc\n",
    "        \n",
    "        if show_value:\n",
    "            print(\"Confusion Matrix:\")\n",
    "            print(self._confusion_matrix)\n",
    "            print(\"Classification Report:\")\n",
    "            print(self._classification_report)\n",
    "\n",
    "    def predict(self) -> list:\n",
    "        \"\"\"\n",
    "        Predicts the class of the input\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise Exception(\"Model not found. Run fit() first.\")\n",
    "        \n",
    "        df = build_dataframe(source_dir=self._stream_csv_dir)\n",
    "        X = df.drop(\n",
    "            [\"filename\", \"class\", \"class_num\"], axis=1\n",
    "        )\n",
    "                \n",
    "        y_pred = self.model.predict(X)\n",
    "        \n",
    "        classnum_pred = y_pred[0]\n",
    "        classname_pred = num_to_class_dict[classnum_pred]\n",
    "        \n",
    "        print(f\"Predicted class: {classname_pred}\")\n",
    "        print(f\"Predicted class number: {classnum_pred}\")\n",
    "         \n",
    "\n",
    "class StreamEmbedder:\n",
    "    def __init__(\n",
    "        self,\n",
    "        stream_video: str,\n",
    "        stream_image_out_dir: str,\n",
    "        stream_csv_out_dir: str,\n",
    "        output_video_path: str,\n",
    "    ):\n",
    "        self.stream_video = stream_video\n",
    "        self.stream_image_out_dir = stream_image_out_dir\n",
    "        self.stream_csv_out_dir = stream_csv_out_dir\n",
    "        self.output_video_path = output_video_path\n",
    "        self.bootstrap_helper = BootstrapHelper(\n",
    "            images_out_folder=stream_image_out_dir,\n",
    "            csvs_out_folder=stream_csv_out_dir,\n",
    "        )\n",
    "\n",
    "    def _get_frame_from_stream(self):\n",
    "        \"\"\"\n",
    "        Returns the next frame from the video stream\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(self.stream_video)\n",
    "        _, frame = cap.read()\n",
    "        cap.release()\n",
    "        return frame\n",
    "\n",
    "    def _save_frame_to_directory(self, frame, directory):\n",
    "        \"\"\"\n",
    "        Saves the given frame to the given directory\n",
    "        \"\"\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        filename = f\"{datetime.now().strftime('%Y%m%d-%H%M%S-%f')}.jpg\"\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        cv2.imwrite(filepath, frame)\n",
    "        \n",
    "    def _remove_image_from_in_out_dir(self) -> None:\n",
    "        target_dir_to_clean_in = os.path.join(self.stream_image_out_dir, \"stream\")\n",
    "        self._clean_directory(directory=target_dir_to_clean_in)\n",
    "\n",
    "    def generate_embbedings(self) -> None:\n",
    "        \"\"\"\n",
    "        Returns the embeddings from the video stream\n",
    "        \"\"\"\n",
    "\n",
    "        self.bootstrap_helper.bootstrap()\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(self.output_video_path, fourcc, 20.0, (640, 480))\n",
    "        while True:\n",
    "            frame = self._get_frame_from_stream()\n",
    "            self._save_frame_to_directory(frame, os.path.join(self.stream_image_out_dir, \"stream\"))\n",
    "            out.write(frame)\n",
    "            cv2.imshow('frame', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                self._save_frame_to_directory(frame, os.path.join(self.stream_image_out_dir, \"stream\"))\n",
    "                break\n",
    "        out.release()\n",
    "        self._remove_image_from_in_out_dir()\n",
    "        cv2.destroyAllWindows()\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os, csv\n",
    "from PIL import Image, ImageDraw\n",
    "import sys\n",
    "import tqdm\n",
    "\n",
    "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
    "from mediapipe.python.solutions import pose as mp_pose\n",
    "\n",
    "from PoseClassification.utils import show_image\n",
    "\n",
    "class BootstrapHelper(object):\n",
    "    \"\"\"Helps to bootstrap images and filter pose samples for classification.\"\"\"\n",
    "\n",
    "    def __init__(self, images_in_folder, images_out_folder, csvs_out_folder):\n",
    "        self._images_in_folder = images_in_folder\n",
    "        self._images_out_folder = images_out_folder\n",
    "        self._csvs_out_folder = csvs_out_folder\n",
    "\n",
    "        # Get list of pose classes and print image statistics.\n",
    "        self._pose_class_names = sorted(\n",
    "            [n for n in os.listdir(self._images_in_folder) if not n.startswith(\".\")]\n",
    "        )\n",
    "\n",
    "    def bootstrap(self, per_pose_class_limit=None):\n",
    "        \"\"\"Bootstraps images in a given folder.\n",
    "\n",
    "        Required image in folder (same use for image out folder):\n",
    "          pushups_up/\n",
    "            image_001.jpg\n",
    "            image_002.jpg\n",
    "            ...\n",
    "          pushups_down/\n",
    "            image_001.jpg\n",
    "            image_002.jpg\n",
    "            ...\n",
    "          ...\n",
    "\n",
    "        Produced CSVs out folder:\n",
    "          pushups_up.csv\n",
    "          pushups_down.csv\n",
    "\n",
    "        Produced CSV structure with pose 3D landmarks:\n",
    "          sample_00001,x1,y1,z1,x2,y2,z2,....\n",
    "          sample_00002,x1,y1,z1,x2,y2,z2,....\n",
    "        \"\"\"\n",
    "        # Create output folder for CVSs.\n",
    "        if not os.path.exists(self._csvs_out_folder):\n",
    "            os.makedirs(self._csvs_out_folder)\n",
    "\n",
    "        for pose_class_name in self._pose_class_names:\n",
    "            print(\"Bootstrapping \", pose_class_name, file=sys.stderr)\n",
    "\n",
    "            # Paths for the pose class.\n",
    "            images_in_folder = os.path.join(self._images_in_folder, pose_class_name)\n",
    "            images_out_folder = os.path.join(self._images_out_folder, pose_class_name)\n",
    "            csv_out_path = os.path.join(self._csvs_out_folder, pose_class_name + \".csv\")\n",
    "            if not os.path.exists(images_out_folder):\n",
    "                os.makedirs(images_out_folder)\n",
    "\n",
    "            with open(csv_out_path, \"w\") as csv_out_file:\n",
    "                csv_out_writer = csv.writer(\n",
    "                    csv_out_file, delimiter=\",\", quoting=csv.QUOTE_MINIMAL\n",
    "                )\n",
    "                # Get list of images.\n",
    "                image_names = sorted(\n",
    "                    [n for n in os.listdir(images_in_folder) if not n.startswith(\".\")]\n",
    "                )\n",
    "                if per_pose_class_limit is not None:\n",
    "                    image_names = image_names[:per_pose_class_limit]\n",
    "\n",
    "                # Bootstrap every image.\n",
    "                for image_name in tqdm.tqdm(image_names):\n",
    "                    # Load image.\n",
    "                    input_frame = cv2.imread(os.path.join(images_in_folder, image_name))\n",
    "                    input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # Initialize fresh pose tracker and run it.\n",
    "                    # with mp_pose.Pose(upper_body_only=False) as pose_tracker:\n",
    "                    with mp_pose.Pose() as pose_tracker:\n",
    "                        result = pose_tracker.process(image=input_frame)\n",
    "                        pose_landmarks = result.pose_landmarks\n",
    "\n",
    "                    # Save image with pose prediction (if pose was detected).\n",
    "                    output_frame = input_frame.copy()\n",
    "                    if pose_landmarks is not None:\n",
    "                        mp_drawing.draw_landmarks(\n",
    "                            image=output_frame,\n",
    "                            landmark_list=pose_landmarks,\n",
    "                            connections=mp_pose.POSE_CONNECTIONS,\n",
    "                        )\n",
    "                    output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
    "                    cv2.imwrite(\n",
    "                        os.path.join(images_out_folder, image_name), output_frame\n",
    "                    )\n",
    "\n",
    "                    # Save landmarks if pose was detected.\n",
    "                    if pose_landmarks is not None:\n",
    "                        # Get landmarks.\n",
    "                        frame_height, frame_width = (\n",
    "                            output_frame.shape[0],\n",
    "                            output_frame.shape[1],\n",
    "                        )\n",
    "                        pose_landmarks = np.array(\n",
    "                            [\n",
    "                                [\n",
    "                                    lmk.x * frame_width,\n",
    "                                    lmk.y * frame_height,\n",
    "                                    lmk.z * frame_width,\n",
    "                                ]\n",
    "                                for lmk in pose_landmarks.landmark\n",
    "                            ],\n",
    "                            dtype=np.float32,\n",
    "                        )\n",
    "                        assert pose_landmarks.shape == (\n",
    "                            33,\n",
    "                            3,\n",
    "                        ), \"Unexpected landmarks shape: {}\".format(pose_landmarks.shape)\n",
    "                        csv_out_writer.writerow(\n",
    "                            [image_name] + pose_landmarks.flatten().astype(str).tolist()\n",
    "                        )\n",
    "\n",
    "                    # Draw XZ projection and concatenate with the image.\n",
    "                    projection_xz = self._draw_xz_projection(\n",
    "                        output_frame=output_frame, pose_landmarks=pose_landmarks\n",
    "                    )\n",
    "                    output_frame = np.concatenate((output_frame, projection_xz), axis=1)\n",
    "\n",
    "    def _draw_xz_projection(self, output_frame, pose_landmarks, r=0.5, color=\"red\"):\n",
    "        frame_height, frame_width = output_frame.shape[0], output_frame.shape[1]\n",
    "        img = Image.new(\"RGB\", (frame_width, frame_height), color=\"white\")\n",
    "\n",
    "        if pose_landmarks is None:\n",
    "            return np.asarray(img)\n",
    "\n",
    "        # Scale radius according to the image width.\n",
    "        r *= frame_width * 0.01\n",
    "\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        for idx_1, idx_2 in mp_pose.POSE_CONNECTIONS:\n",
    "            # Flip Z and move hips center to the center of the image.\n",
    "            x1, y1, z1 = pose_landmarks[idx_1] * [1, 1, -1] + [0, 0, frame_height * 0.5]\n",
    "            x2, y2, z2 = pose_landmarks[idx_2] * [1, 1, -1] + [0, 0, frame_height * 0.5]\n",
    "\n",
    "            draw.ellipse([x1 - r, z1 - r, x1 + r, z1 + r], fill=color)\n",
    "            draw.ellipse([x2 - r, z2 - r, x2 + r, z2 + r], fill=color)\n",
    "            draw.line([x1, z1, x2, z2], width=int(r), fill=color)\n",
    "\n",
    "        return np.asarray(img)\n",
    "\n",
    "    def align_images_and_csvs(self, print_removed_items=False):\n",
    "        \"\"\"Makes sure that image folders and CSVs have the same sample.\n",
    "\n",
    "        Leaves only intersetion of samples in both image folders and CSVs.\n",
    "        \"\"\"\n",
    "        for pose_class_name in self._pose_class_names:\n",
    "            # Paths for the pose class.\n",
    "            images_out_folder = os.path.join(self._images_out_folder, pose_class_name)\n",
    "            csv_out_path = os.path.join(self._csvs_out_folder, pose_class_name + \".csv\")\n",
    "\n",
    "            # Read CSV into memory.\n",
    "            rows = []\n",
    "            with open(csv_out_path) as csv_out_file:\n",
    "                csv_out_reader = csv.reader(csv_out_file, delimiter=\",\")\n",
    "                for row in csv_out_reader:\n",
    "                    rows.append(row)\n",
    "\n",
    "            # Image names left in CSV.\n",
    "            image_names_in_csv = []\n",
    "\n",
    "            # Re-write the CSV removing lines without corresponding images.\n",
    "            with open(csv_out_path, \"w\") as csv_out_file:\n",
    "                csv_out_writer = csv.writer(\n",
    "                    csv_out_file, delimiter=\",\", quoting=csv.QUOTE_MINIMAL\n",
    "                )\n",
    "                for row in rows:\n",
    "                    image_name = row[0]\n",
    "                    image_path = os.path.join(images_out_folder, image_name)\n",
    "                    if os.path.exists(image_path):\n",
    "                        image_names_in_csv.append(image_name)\n",
    "                        csv_out_writer.writerow(row)\n",
    "                    elif print_removed_items:\n",
    "                        print(\"Removed image from CSV: \", image_path)\n",
    "\n",
    "            # Remove images without corresponding line in CSV.\n",
    "            for image_name in os.listdir(images_out_folder):\n",
    "                if image_name not in image_names_in_csv:\n",
    "                    image_path = os.path.join(images_out_folder, image_name)\n",
    "                    os.remove(image_path)\n",
    "                    if print_removed_items:\n",
    "                        print(\"Removed image from folder: \", image_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
